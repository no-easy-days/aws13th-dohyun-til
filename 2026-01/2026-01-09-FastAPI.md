### ASGI와 비동기(Async) 처리

**관련 주제 힌트:** 동기(Sync) vs 비동기(Async), Blocking I/O, Event Loop, Uvicorn, `async` / `await`

**조사 할 때 신경쓰면 좋은 것**

- Python은 원래 느리다고 하는데 FastAPI는 어떻게 Node.js나 Go만큼 빠를 수 있는가? (키워드: ASGI)
- Django나 Flask 같은 먼저 출시된 프레임워크와 달리 FastAPI는 왜 ASGI(비동기 게이트웨이)를 채택해서 속도 혁명을 일으켰는가?

**제프 의견**
처음이라면 어려운 주제지만 이게 **FastAPI를 쓰는 진짜 이유랍니다. 🤖**
단순히 "빠르다"가 아니라 "기다리는 시간을 효율적으로 쓴다"는 개념이지요.
이 원리를 정확하게 이해하시면 서버가 적은 컴퓨터 자원으로도 수만 명의 접속자를 감당할 수 있게 된다는 걸 확실하게 알게 됩니다!

---

## 1️⃣ 프로그램 실행의 기본 단위

### 1.1 프로세스(Process)

- 실행 중인 프로그램의 독립 단위
- 메모리 공간 완전 분리
- 안정성과 격리의 핵심

### 1.2 스레드(Thread)

- 프로세스 내부의 실행 흐름
- 메모리 공유
- 성능과 응답성을 위한 단위

---

## 2️⃣ 왜 멀티프로세스와 멀티스레드가 등장했는가

### 2.1 CPU 낭비 문제

- I/O 대기 중 CPU 유휴
- 단일 실행 흐름의 비효율

### 2.2 멀티프로세스의 등장

- 여러 프로그램 동시 실행
- 장애 격리와 안정성 확보

### 2.3 멀티스레드의 등장

- 같은 프로그램 내부에서 작업 분할
- 메모리 공유를 통한 효율 향상

---

## 3️⃣ CPU Bound와 I/O Bound의 근본적 차이

### 3.1 CPU Bound 작업

- 계산이 병목
- CPU 코어 수가 성능 상한
- 병렬 처리 필요

### 3.2 I/O Bound 작업

- 대기 시간이 병목
- 동시성 구조가 핵심
- 웹 서버의 본질적 특성

---

## 4️⃣ Blocking I/O vs Non-Blocking I/O

### 4.1 Blocking I/O

- 요청 중 대기 시 실행 흐름 정지
- 스레드/프로세스 낭비

### 4.2 Non-Blocking I/O

- 대기 시 제어권 반환
- 다른 작업 처리 가능

---

## 5️⃣ 동시성(Concurrency)과 병렬성(Parallelism)

### 5.1 동시성 (Concurrency)

- 여러 작업을 번갈아 처리
- 구조적 효율 문제
- Event Loop, async/await

### 5.2 병렬성 (Parallelism)

- 여러 작업을 실제로 동시에 실행
- 하드웨어(CPU 코어) 활용
- 멀티프로세스, GPU

---

## 6️⃣ Event Loop의 역할과 의미

### 6.1 Event Loop란 무엇인가

- 실행 가능한 작업만 실행
- I/O 완료 이벤트 기반 스케줄링

### 6.2 단일 스레드 Event Loop의 장점

- 스레드 관리 비용 제거
- Lock, Race Condition 제거
- 높은 동시성 확보

---

## 7️⃣ Python GIL(Global Interpreter Lock)

### 7.1 GIL의 정의

- 한 프로세스에서 한 스레드만 Python 코드 실행

### 7.2 GIL의 탄생 배경

- 참조 카운트 기반 메모리 관리
- 단순성과 안정성 우선 설계

### 7.3 GIL의 영향

- CPU Bound 멀티스레드 병렬 처리 불가
- I/O Bound에서는 문제 없음

---

## 8️⃣ async / await의 진짜 의미

### 8.1 async는 병렬이 아니다

- CPU 계산을 빠르게 하지 않음
- “기다리는 동안 양보”하는 구조

### 8.2 async가 효과적인 조건

- I/O Bound 작업
- Non-blocking 라이브러리 사용

---

## 9️⃣ WSGI와 ASGI의 근본적 차이

### 9.1 WSGI

- 동기 실행 모델
- 요청 하나 = 실행 흐름 하나
- Blocking I/O 기반

### 9.2 ASGI

- 비동기 실행 모델
- 중단/재개 가능한 요청 처리
- Event Loop 기반

---

## 🔟 ASGI 서버와 Uvicorn의 역할

### 10.1 ASGI 서버의 책임

- 포트 오픈
- 요청 수신
- Event Loop 실행
- 애플리케이션 호출

### 10.2 Uvicorn

- ASGI 표준 구현 서버
- uvloop, httptools 기반 고성능
- FastAPI 실행의 실제 주체

---

## 1️⃣1️⃣ FastAPI의 기본 설계 철학

### 11.1 FastAPI는 서버가 아니다

- 요청 처리 로직만 제공
- 실행은 ASGI 서버가 담당

### 11.2 FastAPI가 ASGI를 선택한 이유

- I/O Bound 웹 서버에 최적
- 높은 동시성
- WebSocket, 실시간 통신 지원

---

## 1️⃣2️⃣ 왜 FastAPI는 async + 멀티프로세스를 조합하는가

### 12.1 async의 역할

- I/O 대기 시간 숨김
- Event Loop 기반 동시성

### 12.2 멀티프로세스의 역할

- CPU 코어 활용
- GIL 회피
- 장애 격리

---

## 1️⃣3️⃣ 멀티프로세스 + 단일 스레드 + Event Loop 구조

### 13.1 구조 요약

- 프로세스 = 병렬성
- Event Loop = 동시성

### 13.2 이 구조가 웹 서버에 최적인 이유

- CPU 자원 효율
- 메모리 안정성
- 확장성

---

## 1️⃣4️⃣ 멀티프로세스 vs async 성능 비교 관점

### 14.1 CPU Bound

- async 효과 없음
- 프로세스 수가 성능 결정

### 14.2 I/O Bound

- async 효과 극대화
- 프로세스 증가 효과 제한적

---

## 1️⃣5️⃣ FastAPI에서 CPU Bound 처리 패턴

### 15.1 Event Loop에서 CPU 작업 제거

- async endpoint에서 직접 계산 금지

### 15.2 ThreadPoolExecutor

- 짧은 CPU 작업
- GIL 문제 존재

### 15.3 ProcessPoolExecutor

- 무거운 CPU 작업
- 실제 병렬 처리

### 15.4 완전 분리 구조

- API 서버와 워커 서버 분리
- Celery / Queue / Batch 처리

---

## 1️⃣6️⃣ 현대 웹 서버 설계 공식 (최종 정리)

> 웹 API 서버는
> 
> 
> **멀티프로세스로 병렬성을 확보하고**,
> 
> **단일 스레드 Event Loop로 동시성을 확보하며**,
> 
> **CPU Bound 작업은 반드시 분리한다.**
> 

---

## 1️⃣7️⃣ 이 구조를 이해했다는 의미

- 왜 워커 수를 코어 수로 잡는지 설명 가능
- 왜 async가 병렬이 아닌지 설명 가능
- 왜 CPU 작업을 API 서버에서 빼야 하는지 설명 가능
- FastAPI / Node.js / Nginx 구조 공통점 이해

# 스레드 / 프로세스 / CPU Bound / I/O Bound

### — 서버 성능을 이해하는 최소 단위

---

## 1️⃣ 프로세스(Process)란?

### 🔹 정의

> 실행 중인 프로그램 하나
> 
- 메모리 공간을 **독립적으로 소유**
- 다른 프로세스와 **직접 메모리 공유 불가**

### 🔹 프로세스가 가지는 것

| 구성요소 | 설명 |
| --- | --- |
| 코드 영역 | 실행 코드 |
| 힙(Heap) | 동적 메모리 |
| 스택(Stack) | 함수 호출 |
| 파일 디스크립터 | 열린 파일 |
| PID | 프로세스 ID |

### 🔹 특징

- 안정성 👍 (한 프로세스 죽어도 다른 프로세스 영향 없음)
- 생성 비용 ❌ (메모리/시간 많이 듦)

📌 예시

```
Chrome 실행 → Chrome 프로세스
Python 실행 → Python 프로세스

```

---

## 2️⃣ 스레드(Thread)란?

### 🔹 정의

> 프로세스 안에서 실행되는 작업 흐름
> 
- 같은 프로세스의 **메모리 공유**
- 실행 흐름만 여러 개

### 🔹 스레드가 공유하는 것

| 항목 | 공유 여부 |
| --- | --- |
| 코드 | 공유 |
| 힙 | 공유 |
| 파일 | 공유 |
| 스택 | ❌ 개별 |

### 🔹 특징

- 생성 비용 낮음
- 데이터 공유 쉬움
- ❗ 하나 죽으면 전체 영향 가능

📌 예시

```
Python 프로세스
 ├─ Thread 1 (요청 A)
 ├─ Thread 2 (요청 B)
 └─ Thread 3 (요청 C)

```

---

## 3️⃣ 프로세스 vs 스레드 한눈 비교

| 항목 | 프로세스 | 스레드 |
| --- | --- | --- |
| 메모리 | 완전 분리 | 공유 |
| 생성 비용 | 큼 | 작음 |
| 안정성 | 높음 | 낮음 |
| 통신 | IPC 필요 | 메모리 공유 |
| 사용 예 | 웹 서버 워커 | 요청 처리 |

---

## 4️⃣ CPU Bound란?

### 🔹 정의

> CPU 계산 속도가 성능을 결정하는 작업
> 

### 🔹 특징

- CPU를 **계속 사용**
- I/O 거의 없음
- 코어 수가 중요

### 🔹 예시

- 암호화/복호화
- 이미지 처리
- 머신러닝 추론
- 수학 계산

```
작업 중 시간의 대부분 = CPU 연산

```

📌 성능 올리는 방법

- 멀티프로세스
- 병렬 처리
- C/C++ 확장
- GPU

---

## 5️⃣ I/O Bound란?

### 🔹 정의

> 입출력 대기 시간이 성능을 결정하는 작업
> 

### 🔹 특징

- CPU는 자주 놀고 있음
- 대부분 **기다림**
- 동시성 처리 중요

### 🔹 예시

- DB 조회
- API 호출
- 파일 읽기
- 네트워크 통신

```
작업 중 시간의 대부분 = 대기

```

📌 성능 올리는 방법

- 비동기 처리
- Event Loop
- Connection Pool
- 캐싱

---

## 6️⃣ CPU Bound vs I/O Bound 비교

| 항목 | CPU Bound | I/O Bound |
| --- | --- | --- |
| 병목 | CPU | 대기 |
| 중요 자원 | 코어 | 동시성 |
| async 효과 | ❌ 거의 없음 | ✅ 매우 큼 |
| scaling | 수직 | 수평 |

---

## 7️⃣ 왜 웹 서버는 I/O Bound인가?

### 웹 요청의 실제 흐름

```
요청 수신
→ DB 조회 (대기)
→ 외부 API 호출 (대기)
→ 파일 읽기 (대기)
→ 응답 반환

```

📌 CPU 계산은 몇 ms

📌 대기는 수십~수백 ms

👉 **웹 서버는 본질적으로 I/O Bound**

---

## 8️⃣ 전통적인 서버 모델 (Thread-per-request)

```
요청 1 → Thread 1 → DB 대기
요청 2 → Thread 2 → DB 대기
요청 3 → Thread 3 → DB 대기

```

### 문제점

- 동시 요청 많아지면
    - 스레드 폭증
    - 컨텍스트 스위칭 증가
    - 메모리 고갈

---

## 9️⃣ 비동기 서버 모델 (Event Loop)

```
Thread 1 (Event Loop)
 ├─ 요청 A (DB 대기)
 ├─ 요청 B (API 대기)
 └─ 요청 C (파일 대기)

```

### 장점

- 스레드 1개로 수천 요청
- 대기 시간 낭비 없음
- 메모리 효율 극대화

---

## 🔟 Python에서 중요한 GIL 이야기 (짧게)

### GIL(Global Interpreter Lock)

- Python은 **한 번에 한 스레드만 CPU 실행**
- CPU Bound → 스레드 무의미
- I/O Bound → 문제 없음 (GIL 해제됨)

👉 그래서:

- CPU Bound → 멀티프로세스
- I/O Bound → async / threading

---

## 1️⃣1️⃣ 서버 설계 공식 (실무 기준)

```
웹 API 서버        → I/O Bound → async (FastAPI)
배치/연산 서버     → CPU Bound → multiprocessing

# ASGI와 비동기(Async) 처리

### — FastAPI가 “빠를 수밖에 없는 이유”

---

## 1️⃣ Sync vs Async: 속도의 차이는 “CPU”가 아니라 “기다림”

### 🔹 동기(Sync) 처리

- 한 작업이 **끝날 때까지 다음 작업을 못 함**
- I/O(네트워크, DB, 파일)를 기다리는 동안 **CPU가 놀고 있음**

```
요청 A ── DB 응답 대기 ── 처리 완료
요청 B (대기 중)
요청 C (대기 중)

```

📉 문제점

- 요청 하나가 느리면 **뒤의 요청 전부 정체**
- 동시 접속자 증가 = 스레드/프로세스 폭증

---

### 🔹 비동기(Async) 처리

- **기다리는 동안 다른 요청 처리**
- I/O 대기 시간을 낭비하지 않음

```
요청 A ── DB 대기 ──┐
요청 B ── API 호출 ─┼─ 동시에 진행
요청 C ── 파일 읽기 ─┘

```

📈 결과

- 같은 CPU, 같은 메모리로 **수십 배 트래픽 처리**

👉 핵심:

> 비동기는 “빠르게 계산”하는 게 아니라
“기다리는 시간을 효율적으로 사용”하는 방식이다
> 

---

## 2️⃣ Blocking I/O vs Non-Blocking I/O

### 🔴 Blocking I/O (전통적 서버)

- I/O 요청 → **응답 올 때까지 멈춤**
- 스레드 하나가 묶임

```python
data = requests.get(url)# 응답 올 때까지 정지

```

---

### 🟢 Non-Blocking I/O (비동기 서버)

- I/O 요청 → **이벤트 등록 후 바로 반환**
- 나중에 응답 오면 이어서 실행

```python
data =await httpx.get(url)# 기다리는 동안 다른 작업

```

📌 여기서 중요한 키워드:

- **Event Loop**
- **Callback / await**
- **Coroutine**

---

## 3️⃣ Event Loop: 비동기의 심장

### 🔹 Event Loop란?

- “할 일 목록”을 관리하는 **하나의 관리자**
- 준비된 작업만 실행

```
1. 실행 가능한 작업 확인
2. 하나 실행
3. I/O 끝난 작업 있나 확인
4. 다시 반복

```

📌 특징

- **단일 스레드**
- 컨텍스트 스위칭 거의 없음
- CPU 효율 극대화

---

## 4️⃣ WSGI vs ASGI: 여기서 혁명이 일어남

### 🔴 WSGI (Flask, Django의 전통 방식)

| 특징 | 설명 |
| --- | --- |
| 동기 모델 | 요청당 스레드/프로세스 |
| Blocking I/O | 기다리면 멈춤 |
| HTTP 전용 | WebSocket 불가 |
| 안정적 | 하지만 확장성 낮음 |

```
Client → WSGI → App → Response
(한 요청 = 한 실행 흐름)

```

---

### 🟢 ASGI (FastAPI의 선택)

| 특징 | 설명 |
| --- | --- |
| 비동기 기본 | async / await |
| Event Loop | I/O 대기 중 다른 요청 처리 |
| HTTP + WebSocket | 실시간 통신 가능 |
| 고성능 | 적은 자원으로 고부하 처리 |

```
Client → ASGI → Event Loop → App
             ↳ 여러 요청 동시 처리

```

📌 **FastAPI는 처음부터 ASGI 전용으로 설계됨**

→ “속도 혁명”

---

## 5️⃣ FastAPI + Uvicorn 구조

```
[Client]
   ↓
[Uvicorn]
   ↓
[ASGI Interface]
   ↓
[FastAPI App]
   ↓
[async def endpoint]

```

### 🔹 Uvicorn 역할

- ASGI 서버
- Event Loop 실행
- 비동기 요청 스케줄링

📌 Uvicorn은 내부적으로:

- `uvloop` (C 기반 이벤트 루프)
- `httptools` (고속 HTTP 파서)
    
    를 사용 → **Node.js, Go 급 성능**
    

---

## 6️⃣ Python은 느린데 FastAPI는 왜 빠른가?

### ❌ 오해

> Python = 느리다
> 

### ✅ 진실

> CPU 연산은 느릴 수 있어도
웹 서버는 대부분 I/O 바운드다
> 

### 웹 요청의 실제 시간 비율

- DB 조회
- 외부 API 호출
- 네트워크 대기
- 파일 읽기

👉 **계산보다 기다림이 90%**

FastAPI는:

- 기다리는 동안 다른 요청 처리
- 스레드 생성/파괴 없음
- 메모리 사용량 적음

📌 그래서:

- Node.js와 **비슷한 처리량**
- Go와 **비슷한 응답 지연**

---

## 7️⃣ Django / Flask는 왜 늦게 ASGI를 도입했는가?

### 이유 1️⃣ 시대 차이

- Django (2005), Flask (2010)
- 당시 웹 = 동기 + HTTP

### 이유 2️⃣ 호환성

- 기존 코드 대부분 동기
- ORM, 미들웨어 전부 blocking

### 이유 3️⃣ 설계 철학

- Django: “배터리 포함, 안정성”
- FastAPI: “최신 표준, 성능”

📌 지금은:

- Django ASGI 지원 (Channels)
- Flask도 async 일부 지원
    
    하지만 **태생부터 ASGI인 FastAPI와는 구조가 다름**
    

---

## 8️⃣ async / await의 진짜 의미

```python
@app.get("/users")
asyncdefget_users():
    users =await db.fetch_all()
return users

```

### 중요한 점

- `async` ≠ 무조건 빠름
- `await` ≠ 병렬 실행

👉 의미:

> “여기서 기다려야 하면,
CPU를 다른 요청에게 넘겨라”
> 

---

## 9️⃣ 언제 async가 의미 없을까?

### ❌ 효과 없는 경우

- CPU 연산-heavy 작업
- 이미지 처리
- 머신러닝 추론

➡ 이런 경우:

- 멀티프로세스
- 워커 분리
- Background Task
- Celery / Queue

📌 FastAPI는:

- **I/O 서버**에 최적
- 계산 서버는 분리하는 구조가 정석
ML 추론 서버       → CPU/GPU Bound → 분리

```
